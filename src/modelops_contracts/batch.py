"""Batch and job types for grouped simulation execution.

These types enable efficient execution of multiple related simulations
as a batch, typically from parameter sweeps or sampling strategies.
"""

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional
import hashlib

from .simulation import SimTask
from .errors import ContractViolationError


@dataclass(frozen=True)
class SimBatch:
    """A batch of simulation tasks to run together.

    Groups related tasks that were generated by the same sampling method
    or parameter sweep. This is what science code generates when exploring
    parameter spaces or running sensitivity analyses.

    Attributes:
        batch_id: Unique identifier for this batch
        tasks: List of simulation tasks to execute
        sampling_method: Method used to generate tasks ("grid", "sobol", etc.)
        metadata: Additional metadata about the batch
    """
    batch_id: str
    tasks: List[SimTask]
    sampling_method: str
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        # Validate batch_id
        if not self.batch_id:
            raise ContractViolationError("batch_id must be non-empty")

        # Validate tasks
        if not self.tasks:
            raise ContractViolationError("tasks must contain at least one SimTask")

        for i, task in enumerate(self.tasks):
            if not isinstance(task, SimTask):
                raise ContractViolationError(
                    f"tasks[{i}] must be SimTask, got {type(task).__name__}"
                )

        # Validate sampling_method
        if not self.sampling_method:
            raise ContractViolationError("sampling_method must be non-empty")

        # Known sampling methods (for documentation, not strict validation)
        known_methods = {"grid", "sobol", "random", "lhs", "manual"}
        if self.sampling_method not in known_methods:
            # This is just a warning in metadata, not an error
            if "warnings" not in self.metadata:
                object.__setattr__(self, "metadata", {**self.metadata, "warnings": []})
            self.metadata["warnings"].append(f"Unknown sampling_method: {self.sampling_method}")

    def task_count(self) -> int:
        """Get the number of tasks in this batch."""
        return len(self.tasks)

    def compute_batch_hash(self) -> str:
        """Compute a hash representing all tasks in the batch.

        Returns:
            32-character hex string hash of all task parameters
        """
        # Hash based on all task param_ids for deduplication
        param_ids = [task.params.param_id for task in self.tasks]
        content = "|".join(sorted(param_ids))
        return hashlib.blake2b(content.encode(), digest_size=16).hexdigest()


@dataclass(frozen=True)
class SimJob:
    """A job containing one or more batches for execution.

    This is the top-level unit of work submitted to execution infrastructure
    (Dask, Ray, etc.). A job can contain multiple batches, allowing for
    complex multi-stage simulations or combined sampling strategies.

    Attributes:
        job_id: Unique identifier for this job
        batches: List of simulation batches to execute
        bundle_ref: Reference to the code bundle containing models
        priority: Execution priority (higher = more urgent)
        resource_requirements: Optional resource hints for execution
    """
    job_id: str
    batches: List[SimBatch]
    bundle_ref: str
    priority: int = 0
    resource_requirements: Optional[Dict[str, Any]] = None

    @staticmethod
    def _is_valid_digest(ref: str) -> bool:
        """Check if a bundle reference is a valid digest.

        Args:
            ref: Bundle reference to validate

        Returns:
            True if ref is in format 'sha256:64-hex-chars'
        """
        if not ref or ':' not in ref:
            return False

        parts = ref.split(':', 1)
        if len(parts) != 2:
            return False

        algorithm, hex_digest = parts
        if algorithm != 'sha256':
            return False

        # Check if hex_digest is 64 hex characters
        if len(hex_digest) != 64:
            return False

        try:
            int(hex_digest, 16)  # Validate it's valid hex
            return True
        except ValueError:
            return False

    def __post_init__(self):
        # Validate job_id
        if not self.job_id:
            raise ContractViolationError("job_id must be non-empty")

        # Validate batches
        if not self.batches:
            raise ContractViolationError("batches must contain at least one SimBatch")

        for i, batch in enumerate(self.batches):
            if not isinstance(batch, SimBatch):
                raise ContractViolationError(
                    f"batches[{i}] must be SimBatch, got {type(batch).__name__}"
                )

        # Validate bundle_ref
        if not self.bundle_ref:
            raise ContractViolationError("bundle_ref must be non-empty")

        # Validate bundle_ref is a digest (sha256:64-hex-chars)
        if not self._is_valid_digest(self.bundle_ref):
            raise ContractViolationError(
                f"bundle_ref must be a digest (sha256:64-hex-chars), got: {self.bundle_ref}"
            )

        # Validate priority is reasonable
        if not (-1000 <= self.priority <= 1000):
            raise ContractViolationError(
                f"priority {self.priority} out of reasonable range [-1000, 1000]"
            )

        # Validate all batches reference same bundle
        bundle_refs = {task.bundle_ref for batch in self.batches for task in batch.tasks}
        if len(bundle_refs) > 1:
            raise ContractViolationError(
                f"All tasks must reference the same bundle, found: {bundle_refs}"
            )
        if bundle_refs and self.bundle_ref not in bundle_refs:
            raise ContractViolationError(
                f"Job bundle_ref {self.bundle_ref} doesn't match task bundle_refs {bundle_refs}"
            )

    def total_task_count(self) -> int:
        """Get total number of tasks across all batches."""
        return sum(batch.task_count() for batch in self.batches)

    def get_all_tasks(self) -> List[SimTask]:
        """Get flat list of all tasks across batches."""
        tasks = []
        for batch in self.batches:
            tasks.extend(batch.tasks)
        return tasks

    def compute_job_hash(self) -> str:
        """Compute a hash representing all tasks in the job.

        Returns:
            32-character hex string hash
        """
        batch_hashes = [batch.compute_batch_hash() for batch in self.batches]
        content = f"{self.bundle_ref}|{':'.join(batch_hashes)}"
        return hashlib.blake2b(content.encode(), digest_size=16).hexdigest()


__all__ = ["SimBatch", "SimJob"]